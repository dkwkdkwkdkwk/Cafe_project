import time
import json
import os
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import NoSuchElementException, TimeoutException

# âœ… ë°±ì—… íŒŒì¼ ë¡œë“œ
def load_backup():
    try:
        with open("backup.json", "r", encoding="utf-8") as f:
            data = json.load(f)
            return data.get("page", 1), set(data.get("collected_cafes", [])), data.get("cafes", [])
    except FileNotFoundError:
        return 1, set(), []

# âœ… ë°±ì—… ì €ì¥
def save_backup(page, collected_cafes, cafes):
    backup_data = {
        "page": page,
        "collected_cafes": list(collected_cafes),
        "cafes": cafes
    }
    with open("backup.json", "w", encoding="utf-8") as f:
        json.dump(backup_data, f, ensure_ascii=False, indent=2)

# âœ… ë“œë¼ì´ë²„ ì—´ê¸°
def open_driver():
    driver_path = "C:/CapStone/VCC/chromedriver.exe"
    service = Service(driver_path)
    options = webdriver.ChromeOptions()
    options.add_argument("--start-maximized")
    driver = webdriver.Chrome(service=service, options=options)
    return driver

# âœ… iframe ëŒ€ê¸° í•¨ìˆ˜
def wait_for_iframe(driver, iframe_id="searchIframe"):
    driver.switch_to.default_content()
    WebDriverWait(driver, 20).until(EC.frame_to_be_available_and_switch_to_it((By.ID, iframe_id)))

# âœ… ìŠ¤í¬ë¡¤ í•¨ìˆ˜
def scroll_down_all(driver):
    wait_for_iframe(driver)
    scroll_area = driver.find_element(By.CSS_SELECTOR, "div#_pcmap_list_scroll_container")
    last_height = driver.execute_script("return arguments[0].scrollHeight", scroll_area)
    scroll_try = 0
    while True:
        driver.execute_script("arguments[0].scrollBy(0, 3000);", scroll_area)
        time.sleep(1.5)
        new_height = driver.execute_script("return arguments[0].scrollHeight", scroll_area)
        if new_height == last_height:
            scroll_try += 1
            if scroll_try > 3:
                break
        else:
            scroll_try = 0
        last_height = new_height
    print("âœ… ì¹´í˜ ë¦¬ìŠ¤íŠ¸ ìŠ¤í¬ë¡¤ ì™„ë£Œ")

# âœ… ë©”ë‰´íŒ ì´ë¯¸ì§€ ê¸ê¸°
def crawl_menu_images(driver):
    image_urls = []
    try:
        menu_section = driver.find_elements(By.CSS_SELECTOR, "h2.place_section_header")
        for section in menu_section:
            title = section.find_element(By.CSS_SELECTOR, "div.place_section_header_title").text.strip()
            if "ë©”ë‰´íŒ ì´ë¯¸ì§€ë¡œ ë³´ê¸°" in title:
                parent = section.find_element(By.XPATH, "..")
                images = parent.find_elements(By.CSS_SELECTOR, "img.K0PDV")
                for img in images:
                    src = img.get_attribute("src")
                    image_urls.append(src)
                break
    except Exception as e:
        print(f"â— ë©”ë‰´íŒ ì´ë¯¸ì§€ ê¸ê¸° ì‹¤íŒ¨: {e}")
    return image_urls

# âœ… ì¹´í˜ ë©”ë‰´ ê¸ê¸°
def crawl_menus(driver, name, category, address):
    final_menus = []
    try:
        tabs = driver.find_elements(By.CSS_SELECTOR, "span.veBoZ")
        found_menu_tab = False
        for tab in tabs:
            if tab.text.strip() == "ë©”ë‰´":
                driver.execute_script("arguments[0].click();", tab)
                print("âœ… ë©”ë‰´íƒ­ í´ë¦­ ì™„ë£Œ")
                time.sleep(2)
                found_menu_tab = True
                break

        if not found_menu_tab:
            print(f"â— {name} : ë©”ë‰´íƒ­ ì—†ìŒ â†’ ì¹´í˜ ìŠ¤í‚µ")
            return []

        tab_buttons = driver.find_elements(By.CSS_SELECTOR, "div.category_box_inner button.tab")
        for tab in tab_buttons:
            try:
                tab_text = tab.find_element(By.CSS_SELECTOR, "span.tab_text").text.strip()
                print(f"â¡ íƒ­ í´ë¦­: {tab_text}")
                driver.execute_script("arguments[0].click();", tab)
                time.sleep(1.5)

                groups = driver.find_elements(By.CSS_SELECTOR, "div.order_list_inner")
                for group in groups:
                    while True:
                        try:
                            more_button = group.find_element(By.CSS_SELECTOR, "button.GYkZu")
                            driver.execute_script("arguments[0].click();", more_button)
                            time.sleep(1.5)
                        except:
                            break

                    try:
                        group_title = group.find_element(By.CSS_SELECTOR, "div.order_list_tit span.title").text.strip()
                    except:
                        group_title = "ê¸°ë³¸ë©”ë‰´"

                    items = group.find_elements(By.CSS_SELECTOR, "ul.order_list_area li.order_list_item")
                    if not items:
                        continue

                    for item in items:
                        try:
                            menu_name = item.find_element(By.CSS_SELECTOR, "div.tit").text.strip()
                        except:
                            menu_name = "ë©”ë‰´ì—†ìŒ"
                        try:
                            price = item.find_element(By.CSS_SELECTOR, "div.price strong").text.strip()
                            if "ë³€ë™" in price or price == "":
                                price = "-"
                            else:
                                price += "ì›"
                        except:
                            price = "-"

                        if menu_name == "ë©”ë‰´ì—†ìŒ" or price == "-":
                            continue

                        final_menus.append({
                            "ì¹´í˜ëª…": name,
                            "ì¹´í…Œê³ ë¦¬": category,
                            "ì£¼ì†Œ": address,
                            "ë©”ë‰´ê·¸ë£¹": group_title,
                            "ë©”ë‰´": menu_name,
                            "ê°€ê²©": price,
                            "menu_type": "ë©”ë‰´"
                        })
            except Exception as e:
                print(f"â— íƒ­ ë‚´ë¶€ í´ë¦­ ì‹¤íŒ¨: {e}")
                continue

        while True:
            try:
                more_button = driver.find_element(By.CSS_SELECTOR, "a.fvwqf")
                driver.execute_script("arguments[0].click();", more_button)
                print("âœ… ê·¸ë£¹í™” ì•ˆëœ ë©”ë‰´ ë”ë³´ê¸° í´ë¦­")
                time.sleep(2)
            except NoSuchElementException:
                break
            except Exception as e:
                print(f"â— ê·¸ë£¹í™” ì•ˆëœ ë©”ë‰´ ë”ë³´ê¸° í´ë¦­ ì‹¤íŒ¨: {e}")
                break

        plain_items = driver.find_elements(By.CSS_SELECTOR, "ul > li.E2jtL")
        for item in plain_items:
            try:
                menu_name = item.find_element(By.CSS_SELECTOR, "span.lPzHi").text.strip()
            except:
                menu_name = "ë©”ë‰´ì—†ìŒ"
            try:
                price = item.find_element(By.CSS_SELECTOR, "div.GXS1X").text.strip()
                if "ë³€ë™" in price or price == "":
                    price = "-"
                else:
                    price += "ì›"
            except:
                price = "-"

            if menu_name == "ë©”ë‰´ì—†ìŒ" or price == "-":
                continue

            final_menus.append({
                "ì¹´í˜ëª…": name,
                "ì¹´í…Œê³ ë¦¬": category,
                "ì£¼ì†Œ": address,
                "ë©”ë‰´ê·¸ë£¹": "ê·¸ë£¹ì—†ìŒ",
                "ë©”ë‰´": menu_name,
                "ê°€ê²©": price,
                "menu_type": "ë©”ë‰´"
            })

        menu_images = crawl_menu_images(driver)
        for img_url in menu_images:
            final_menus.append({
                "ì¹´í˜ëª…": name,
                "ì¹´í…Œê³ ë¦¬": category,
                "ì£¼ì†Œ": address,
                "ë©”ë‰´ê·¸ë£¹": "ë©”ë‰´íŒì´ë¯¸ì§€",
                "ë©”ë‰´": img_url,
                "ê°€ê²©": "-",
                "menu_type": "ë©”ë‰´íŒì´ë¯¸ì§€"
            })

    except Exception as e:
        print(f"â— ë©”ë‰´ ê¸ê¸° ì „ì²´ ì‹¤íŒ¨: {e}")

    return final_menus

# (ë©”ì¸ ì‹¤í–‰ ë¶€ë¶„ ê³„ì† ì´ì–´ì„œ)

while True:
    page, collected_cafes, cafes = load_backup()
    driver = open_driver()
    try:
        driver.get("https://map.naver.com/v5/search")
        wait = WebDriverWait(driver, 20)
        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "input.input_search")))

        search_box = driver.find_element(By.CSS_SELECTOR, "input.input_search")
        search_box.click()
        search_box.clear()
        search_box.send_keys("ì˜ë“±í¬êµ¬ ì¹´í˜")
        search_box.send_keys(Keys.ENTER)
        time.sleep(1.5)
        search_box.send_keys(Keys.ENTER)
        time.sleep(3)

        while True:
            print(f"\nğŸ“„ ì˜ë“±í¬êµ¬ - í˜ì´ì§€ {page} ì‹œì‘!")
            wait_for_iframe(driver)
            scroll_down_all(driver)

            items = driver.find_elements(By.CSS_SELECTOR, "li.UEzoS")
            print(f"ğŸ‘‰ í˜„ì¬ í˜ì´ì§€ ì¹´í˜ ìˆ˜: {len(items)}ê°œ")

            cafe_links = []
            for item in items:
                try:
                    name = item.find_element(By.CSS_SELECTOR, "span.TYaxT").text.strip()
                    category = item.find_element(By.CSS_SELECTOR, "span.KCMnt").text.strip()
                    link = item.find_element(By.CSS_SELECTOR, "a.tzwk0")
                    cafe_links.append((name, category, link))
                except:
                    continue

            for idx, (name, category, link) in enumerate(cafe_links):
                if name in collected_cafes:
                    print(f"â— ì´ë¯¸ ìˆ˜ì§‘í•œ ì¹´í˜ {name} â†’ ìŠ¤í‚µ")
                    continue
                collected_cafes.add(name)

                try:
                    wait_for_iframe(driver)
                    driver.execute_script("arguments[0].click();", link)
                    time.sleep(2)
                    wait_for_iframe(driver, "entryIframe")
                    time.sleep(2)

                    try:
                        address = driver.find_element(By.CSS_SELECTOR, "span.LDgIH").text.strip()
                    except:
                        address = "-"

                    menus = crawl_menus(driver, name, category, address)
                    if menus:
                        cafes.extend(menus)

                    driver.back()
                    time.sleep(2)

                except Exception as e:
                    print(f"â— ì¹´í˜ ì§„ì… ì‹¤íŒ¨: {e}")
                    driver.refresh()
                    time.sleep(5)
                    continue

            save_backup(page, collected_cafes, cafes)

            driver.switch_to.default_content()
            wait_for_iframe(driver)
            next_buttons = driver.find_elements(By.CSS_SELECTOR, "a.eUTV2[aria-disabled='false']")
            moved = False
            for btn in next_buttons:
                label = btn.find_element(By.CSS_SELECTOR, "span.place_blind").text.strip()
                if label == "ë‹¤ìŒí˜ì´ì§€":
                    driver.execute_script("arguments[0].click();", btn)
                    moved = True
                    print("â¡ ë‹¤ìŒ í˜ì´ì§€ ì´ë™ ì¤‘...")
                    time.sleep(3)
                    break
            if not moved:
                print("\nâ— ë” ì´ìƒ ë‹¤ìŒ í˜ì´ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
                break
            page += 1

    except Exception as e:
        print(f"\nâ— ì—ëŸ¬ ë°œìƒ: {e}")
        driver.quit()
        time.sleep(5)
        continue

    else:
        save_path = "ì˜ë“±í¬êµ¬_ì¹´í˜.json"
        with open(save_path, "w", encoding="utf-8") as f:
            json.dump(cafes, f, ensure_ascii=False, indent=2)
        print(f"\nâœ… (ì—ëŸ¬ ë°œìƒ ì—¬ë¶€ ê´€ê³„ì—†ì´) ì €ì¥ ì™„ë£Œ: {save_path}")

        if os.path.exists("backup.json"):
            os.remove("backup.json")
            print("âœ… ë°±ì—…íŒŒì¼ ì‚­ì œ ì™„ë£Œ")

        driver.quit()
        break
